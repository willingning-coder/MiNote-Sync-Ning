# -*- coding: utf-8 -*-
"""
Project: MiNote-Sync Pro (å°ç±³ç¬”è®°åŒæ­¥åŠ©æ‰‹)
Author: Ning (willingning-coder)
Date: 2025-12-29
Version: 1.1.0 (Robust Edition)

Changelog:
    v1.1.0: 
      - ä¿®å¤ HTML æ ‡ç­¾æ¸…æ´—ä¸å½»åº•å¯¼è‡´â€œåƒåœ¾ä¿¡æ¯â€æ®‹ç•™çš„é—®é¢˜ã€‚
      - æ–°å¢æ–‡ä»¶ç³»ç»Ÿæ—¶é—´æˆ³åŒæ­¥ (os.utime)ï¼Œè®©æ–‡ä»¶ä¿®æ”¹æ—¶é—´å›å½’ç¬”è®°çœŸå®æ—¶é—´ã€‚
      - æ–°å¢æŒ‡æ•°é€€é¿é‡è¯•æœºåˆ¶ (Exponential Backoff)ï¼Œå½»åº•è§£å†³â€œæ— æ³•è·å–è¯¦æƒ…â€çš„ç½‘ç»œæ³¢åŠ¨æŠ¥é”™ã€‚
    v1.0.2: 
      - ä¿®å¤åˆ—è¡¨æŠ“å–æ­»å¾ªç¯ã€‚
"""

import json
import os
import re
import requests
import time
import html
import random
from concurrent.futures import ThreadPoolExecutor

# ================= 1. é…ç½®åŒº =================

BASE_DIR = os.getcwd()
VAULT_ROOT = os.path.join(BASE_DIR, "Data", "Notes")
ASSETS_DIR = os.path.join(VAULT_ROOT, "assets")

# Cookie å…¨å±€å˜é‡
COOKIE = "" 

# ================= 2. æ ¸å¿ƒå·¥å…·åº“ =================

def get_headers():
    global COOKIE
    if not COOKIE:
        print("\n" + "="*50)
        print("ğŸ”’ ä¸ºäº†ä¿æŠ¤éšç§ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥ Cookie")
        print("   1. ç™»å½• https://i.mi.com/note/h5")
        print("   2. æŒ‰ F12 æ‰“å¼€æ§åˆ¶å° -> ç½‘ç»œ(Network)")
        print("   3. åˆ·æ–°é¡µé¢ï¼Œç‚¹å‡»ä»»æ„è¯·æ±‚ï¼Œå¤åˆ¶è¯·æ±‚å¤´ä¸­çš„ Cookie")
        print("="*50)
        COOKIE = input("ğŸ‘‰ è¯·ç²˜è´´ Cookie å¹¶å›è½¦: ").strip()
    
    return {
        "Cookie": COOKIE,
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36",
        "Referer": "https://i.mi.com/note/h5",
        "Origin": "https://i.mi.com"
    }

def request_with_retry(url, headers, retries=3, stream=False):
    """
    ã€é«˜é˜¶ä¿®å¤ã€‘æŒ‡æ•°é€€é¿é‡è¯•æœºåˆ¶
    è§£å†³ Issue #1: "åŒæ­¥è¿‡ç¨‹ä¸­å‡ºç°è­¦å‘Šæ— æ³•è·å–è¯¦æƒ…"
    åŸç†ï¼šå¤±è´¥åç­‰å¾… 1s, 2s, 4s... é¿å…å› ç½‘ç»œæŠ–åŠ¨ç›´æ¥ç†”æ–­
    """
    for i in range(retries):
        try:
            response = requests.get(url, headers=headers, stream=stream, timeout=15)
            # é’ˆå¯¹ API é™åˆ¶çš„ 403/429/502 é”™è¯¯è¿›è¡Œç‰¹å®šé‡è¯•
            if response.status_code in [200, 404]:
                return response
            elif response.status_code in [403, 429, 500, 502, 503]:
                raise ValueError(f"Server Error {response.status_code}")
        except Exception as e:
            wait_time = (1 * (2 ** i)) + random.uniform(0, 1) # å¢åŠ éšæœºæŠ–åŠ¨
            if i < retries - 1:
                print(f"    âš ï¸ è¯·æ±‚ä¸ç¨³å®šï¼Œ{wait_time:.1f}ç§’åé‡è¯•... ({e})")
                time.sleep(wait_time)
            else:
                print(f"    âŒ é‡è¯•è€—å°½ï¼Œè¯·æ±‚å¤±è´¥: {url}")
                return None
    return None

def setup_dirs():
    if not os.path.exists(VAULT_ROOT): os.makedirs(VAULT_ROOT)
    if not os.path.exists(ASSETS_DIR): os.makedirs(ASSETS_DIR)

def sanitize_filename(name):
    if not name: return "æœªå‘½å"
    # ç§»é™¤ä¸å¯è§å­—ç¬¦å’Œéæ³•è·¯å¾„å­—ç¬¦
    name = re.sub(r'[\x00-\x1f]', '', name)
    return re.sub(r'[\\/*?:"<>|]', "", name).replace('\n', ' ').strip()[:80]

def clean_content(content):
    """
    ã€é«˜é˜¶ä¿®å¤ã€‘æ·±åº¦æ¸…æ´— HTML/XML åƒåœ¾ä»£ç 
    è§£å†³ Issue #2: "åŒæ­¥å¥½çš„æ–‡ä»¶ä¾ç„¶æœ‰åƒåœ¾ä¿¡æ¯"
    """
    if not content: return ""
    
    # 1. å°† HTML æ¢è¡Œç¬¦è½¬æ¢ä¸º Markdown æ¢è¡Œ
    content = content.replace("<br>", "\n").replace("<br/>", "\n")
    content = content.replace("</div>", "\n").replace("</p>", "\n")
    
    # 2. ç§»é™¤ç‰¹å®šæ ‡ç­¾ä¿ç•™å†…å®¹ (å¦‚ text, background)
    content = re.sub(r'<text[^>]*>(.*?)</text>', r'\1', content, flags=re.S)
    content = re.sub(r'<background[^>]*>(.*?)</background>', r'\1', content, flags=re.S)
    
    # 3. æš´åŠ›ç§»é™¤æ‰€æœ‰å‰©ä½™çš„ <xxx> æ ‡ç­¾ (æ¸…ç† div, font, span ç­‰)
    content = re.sub(r'<[^>]+>', '', content)
    
    # 4. è§£ç  HTML å®ä½“ (å¦‚ &nbsp; -> ç©ºæ ¼, &lt; -> <)
    content = html.unescape(content)
    
    return content.strip()

def get_real_extension(response):
    ctype = response.headers.get("Content-Type", "").lower()
    if "amr" in ctype: return ".amr"
    if "wav" in ctype: return ".wav"
    if "mpeg" in ctype or "mp3" in ctype or "audio" in ctype: return ".mp3"
    if "png" in ctype: return ".png"
    if "gif" in ctype: return ".gif"
    if "jpeg" in ctype or "jpg" in ctype: return ".jpg"
    return ".jpg"

# ================= 3. ä¸šåŠ¡é€»è¾‘åŒº =================

def download_resource(fid):
    # å¢é‡è·³è¿‡æ£€æŸ¥
    for ext in [".jpg", ".png", ".gif", ".mp3", ".amr", ".wav", ".m4a", ".webp"]:
        fname = f"{fid}{ext}"
        fpath = os.path.join(ASSETS_DIR, fname)
        if os.path.exists(fpath) and os.path.getsize(fpath) > 1000:
            return fname

    headers = get_headers()
    types = ["note_img", "file", "note_voice", "note_audio"]
    
    for tp in types:
        url = f"https://i.mi.com/file/full?type={tp}&fileid={fid}"
        # ä½¿ç”¨é‡è¯•æœºåˆ¶ä¸‹è½½èµ„æº
        r = request_with_retry(url, headers, retries=2, stream=True)
        if r and r.status_code == 200:
            if int(r.headers.get('content-length', 0)) < 1000: continue
            real_ext = get_real_extension(r)
            fname = f"{fid}{real_ext}"
            try:
                with open(os.path.join(ASSETS_DIR, fname), "wb") as f:
                    for chunk in r.iter_content(1024): f.write(chunk)
                return fname
            except Exception as e:
                print(f"    âš ï¸ å†™å…¥èµ„æºå¤±è´¥: {e}")
    return None

def fetch_note_list():
    print("ğŸ“¡ æ­£åœ¨è¿æ¥å°ç±³äº‘æœåŠ¡...")
    headers = get_headers()
    all_entries = []
    folders_map = {'0': 'æœªåˆ†ç±»'}
    sync_tag = None
    max_pages = 500 
    current_page = 0
    
    while True:
        current_page += 1
        url = f"https://i.mi.com/note/full/page/?limit=200&ts={int(time.time()*1000)}"
        if sync_tag: url += f"&syncTag={sync_tag}"
        
        # ä½¿ç”¨é‡è¯•æœºåˆ¶è·å–åˆ—è¡¨
        r = request_with_retry(url, headers)
        
        if not r:
            print("âŒ ç½‘ç»œè¿æ¥ä¸¥é‡é”™è¯¯ï¼Œæ— æ³•è·å–åˆ—è¡¨ã€‚")
            break
            
        if r.status_code == 401:
            print("âŒ Cookie å·²å¤±æ•ˆï¼Œè¯·é‡æ–°è·å–ï¼")
            return None, None
        
        try:
            json_data = r.json()
            data = json_data.get('data', {})
            
            for f in data.get('folders', []):
                folders_map[str(f.get('id'))] = f.get('subject')
            
            entries = data.get('entries', [])
            if not entries:
                print("    âœ… å·²åˆ°è¾¾æœ€åä¸€é¡µï¼Œåœæ­¢æŠ“å–åˆ—è¡¨ã€‚")
                break
            
            all_entries.extend(entries)
            print(f"    å·²ç´¢å¼• {len(all_entries)} æ¡ç¬”è®° (ç¬¬ {current_page} é¡µ)...")
            
            sync_tag = data.get('syncTag')
            if not sync_tag or current_page >= max_pages: 
                break
            
            time.sleep(0.5) # åŸºç¡€é™æµ
        except Exception as e:
            print(f"âŒ è§£æåˆ—è¡¨æ•°æ®å¤±è´¥: {e}")
            break
            
    return all_entries, folders_map

def fetch_note_detail(note_id):
    url = f"https://i.mi.com/note/note/{note_id}/?ts={int(time.time()*1000)}"
    # ä½¿ç”¨é‡è¯•æœºåˆ¶
    r = request_with_retry(url, get_headers(), retries=3)
    if r and r.status_code == 200:
        return r.json().get('data', {}).get('entry')
    return None

def process_single_note(args):
    """å•æ¡ç¬”è®°å¤„ç†æµç¨‹"""
    try:
        entry, folder_map = args
        nid = entry['id']
        
        # 1. åŸºç¡€å…ƒæ•°æ®æå–
        folder_id = str(entry.get('folderId', '0'))
        folder_name = folder_map.get(folder_id, "æœªåˆ†ç±»")
        
        extra = {}
        try: extra = json.loads(entry.get('extraInfo', '{}'))
        except: pass
        
        title = extra.get('title') or entry.get('snippet', 'æ— æ ‡é¢˜')
        title = sanitize_filename(title)
        if not title: title = f"æ— æ ‡é¢˜_{nid}"
        
        # 2. å‡†å¤‡æ–‡ä»¶è·¯å¾„
        date_str = time.strftime("%Y%m%d", time.localtime(entry['createDate']/1000))
        target_dir = os.path.join(VAULT_ROOT, sanitize_filename(folder_name))
        md_path = os.path.join(target_dir, f"{date_str}_{title}.md")
        
        # 3. å¢é‡æ£€æµ‹ (å¦‚æœæœ¬åœ°å·²å­˜åœ¨ä¸”æ–‡ä»¶å¤§å°>0ï¼Œè·³è¿‡)
        if os.path.exists(md_path) and os.path.getsize(md_path) > 0:
            print(f"    â­ï¸ [è·³è¿‡] æœ¬åœ°å·²å­˜åœ¨: {title}")
            return 
            
        # 4. è·å–è¯¦æƒ… (å«é‡è¯•)
        full_note = fetch_note_detail(nid)
        if not full_note: 
            print(f"    âš ï¸ [è­¦å‘Š] æ— æ³•è·å–è¯¦æƒ… (é‡è¯•è€—å°½): {title}")
            return

        content = full_note.get('content', '')
        
        if not os.path.exists(target_dir): 
            os.makedirs(target_dir, exist_ok=True)
        
        # 5. èµ„æºæå–ä¸ä¸‹è½½
        ids = set()
        ids.update(re.findall(r'fileid=["\']?([\w\.\-]+)["\']?', content, re.I))
        ids.update(re.findall(r'â˜º\s*([\w\.\-]+)', content))
        ids.update(re.findall(r'<fileId:(\d+)', content))
        ids.update(re.findall(r'<sound[^>]+fileid=["\']?([\w\.\-]+)["\']?', content, re.I))
        
        voice_list = extra.get('voice_list') or extra.get('audio_list') or []
        voice_ids = [v['fileId'] for v in voice_list if v.get('fileId')]
        ids.update(voice_ids)
        
        if full_note.get('setting'):
            try:
                for res in json.loads(full_note.get('setting', '{}')).get('data', []):
                    if res.get('fileId'): ids.add(res.get('fileId'))
            except: pass

        replacements = {}
        for fid in ids:
            fname = download_resource(fid)
            if fname:
                replacements[fid] = f"![[{fname}]]"

        # 6. å†…å®¹æ·±åº¦æ¸…æ´—ä¸æ›¿æ¢
        content = clean_content(content) # ä½¿ç”¨æ–°çš„æ¸…æ´—å‡½æ•°
        
        for fid, link in replacements.items():
            content = re.sub(fr'<sound[^>]*{re.escape(fid)}[^>]*\/?>', f"\n{link}\n", content)
            content = re.sub(fr'<[^>]*{re.escape(fid)}[^>]*>', f"\n{link}\n", content)
            content = re.sub(fr'â˜º\s*{re.escape(fid)}.*', f"\n{link}\n", content)
            content = content.replace(f"<fileId:{fid}>", f"\n{link}\n")
            content = content.replace(f"<fileId:{fid}/>", f"\n{link}\n")

        if voice_ids:
            appended = False
            for vid in voice_ids:
                if vid not in content and vid in replacements:
                    if not appended:
                        content += "\n\n---\n**ğŸ™ï¸ é™„ä»¶å½•éŸ³ï¼š**\n"
                        appended = True
                    content += f"{replacements[vid]}\n"

        # 7. ç”Ÿæˆ Markdown æ–‡ä»¶
        ctime_struct = time.localtime(full_note['createDate']/1000)
        mtime_struct = time.localtime(full_note['modifyDate']/1000)
        ctime_str = time.strftime("%Y-%m-%d %H:%M:%S", ctime_struct)
        mtime_str = time.strftime("%Y-%m-%d %H:%M:%S", mtime_struct)
        
        md_text = f"---\nid: {nid}\ncreated: {ctime_str}\nupdated: {mtime_str}\ntitle: \"{title}\"\nfolder: \"{folder_name}\"\nauthor: Ning\n---\n\n# {title}\n\n{content}\n"
        
        with open(md_path, "w", encoding="utf-8") as f:
            f.write(md_text)
            
        # 8. ã€æ ¸å¿ƒä¿®å¤ã€‘å¼ºåˆ¶ä¿®æ”¹æ–‡ä»¶ç³»ç»Ÿæ—¶é—´æˆ³
        # è§£å†³ Issue #2: "å®šæ ¼éƒ½æ˜¯åˆ›å»ºæ—¥æœŸ"
        try:
            mtime_timestamp = full_note['modifyDate'] / 1000.0
            # os.utime(path, (access_time, modification_time))
            os.utime(md_path, (mtime_timestamp, mtime_timestamp))
        except Exception as e:
            pass # æ—¶é—´æˆ³ä¿®æ”¹å¤±è´¥ä¸å½±å“æ–‡ä»¶å†…å®¹ï¼Œé™é»˜å¤„ç†

        print(f"    âœ… [åŒæ­¥æˆåŠŸ] [{folder_name}] {title}")
        
    except Exception as e:
        print(f"    âŒ [é”™è¯¯] å¤„ç†ç¬”è®° {entry.get('id', 'Unknown')} å¤±è´¥: {e}")

def main():
    print(f"ğŸš€ MiNote Sync Pro - By Ning (v1.1.0 Robust)")
    setup_dirs()
    
    notes_list, folder_map = fetch_note_list()
    if not notes_list: 
        print("âš ï¸ æœªå‘ç°ç¬”è®°æˆ– Cookie å¤±æ•ˆ")
        return

    print(f"ğŸ“¦ å‘ç°äº‘ç«¯ç¬”è®° {len(notes_list)} æ¡ï¼Œå‡†å¤‡å¼€å§‹åŒæ­¥...")
    print(f"âš™ï¸  çº¿ç¨‹æ± æ¨¡å¼ (Max Workers: 4) - é™ä½å¹¶å‘ä»¥æé«˜ç¨³å®šæ€§")
    
    # é™ä½å¹¶å‘æ•°ï¼Œé…åˆé‡è¯•æœºåˆ¶ï¼Œç¡®ä¿ç¨³å®šæ€§
    with ThreadPoolExecutor(max_workers=4) as pool:
        pool.map(process_single_note, [(n, folder_map) for n in notes_list])
        
    print(f"\nğŸ‰ å…¨éƒ¨åŒæ­¥å®Œæˆï¼æ•°æ®å·²ä¿å­˜è‡³: {VAULT_ROOT}")

if __name__ == "__main__":
    main()
