# -*- coding: utf-8 -*-
"""
Project: MiNote-Sync (å°ç±³ç¬”è®°åŒæ­¥åŠ©æ‰‹)
Author: Ning (willingning-coder)
Date: 2025-12-26
Version: 1.0.0

Description:
    å…¨ç½‘æœ€å®Œå–„çš„å°ç±³ç¬”è®°å¯¼å‡º/åŒæ­¥æ–¹æ¡ˆã€‚
    æ”¯æŒæ–‡ä»¶å¤¹åˆ†ç±»ã€å½•éŸ³/å›¾ç‰‡å®Œç¾ä¸‹è½½ï¼ˆä¿®å¤é•¿IDé—®é¢˜ï¼‰ã€å¢é‡æ›´æ–°ã€Obsidian æ·±åº¦é€‚é…ã€‚
    
    This tool is designed to sync Xiaomi Notes to local Markdown files 
    optimized for Obsidian, featuring incremental updates and audio repair.
"""

import json
import os
import re
import requests
import time
from concurrent.futures import ThreadPoolExecutor

# ================= 1. é…ç½®åŒº =================

# é»˜è®¤å°†ç¬”è®°ä¿å­˜åœ¨å½“å‰è„šæœ¬ç›®å½•ä¸‹çš„ "Data" æ–‡ä»¶å¤¹ä¸­
BASE_DIR = os.getcwd()
VAULT_ROOT = os.path.join(BASE_DIR, "Data", "Notes")
ASSETS_DIR = os.path.join(VAULT_ROOT, "assets")

# Cookie å…¨å±€å˜é‡
COOKIE = "" 

# ================= 2. æ ¸å¿ƒé€»è¾‘åŒº =================

def get_headers():
    global COOKIE
    if not COOKIE:
        print("\n" + "="*50)
        print("ğŸ”’ ä¸ºäº†ä¿æŠ¤éšç§ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥ Cookie")
        print("   1. ç™»å½• https://i.mi.com/note/h5")
        print("   2. æŒ‰ F12 æ‰“å¼€æ§åˆ¶å° -> ç½‘ç»œ(Network)")
        print("   3. åˆ·æ–°é¡µé¢ï¼Œç‚¹å‡»ä»»æ„è¯·æ±‚ï¼Œå¤åˆ¶è¯·æ±‚å¤´ä¸­çš„ Cookie")
        print("="*50)
        COOKIE = input("ğŸ‘‰ è¯·ç²˜è´´ Cookie å¹¶å›è½¦: ").strip()
    
    return {
        "Cookie": COOKIE,
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36",
        "Referer": "https://i.mi.com/note/h5",
        "Origin": "https://i.mi.com"
    }

def setup_dirs():
    if not os.path.exists(VAULT_ROOT): os.makedirs(VAULT_ROOT)
    if not os.path.exists(ASSETS_DIR): os.makedirs(ASSETS_DIR)

def sanitize_filename(name):
    """æ¸…æ´—æ–‡ä»¶åï¼Œé˜²æ­¢ç³»ç»ŸæŠ¥é”™"""
    return re.sub(r'[\\/*?:"<>|]', "", name).replace('\n', ' ').strip()[:50]

def clean_content(content):
    """æ·±åº¦æ¸…æ´— XML åƒåœ¾ä»£ç """
    if not content: return ""
    content = re.sub(r'<text[^>]*>(.*?)</text>', r'\1', content, flags=re.S)
    content = re.sub(r'<background[^>]*>(.*?)</background>', r'\1', content, flags=re.S)
    content = content.replace('&nbsp;', ' ').replace('&lt;', '<').replace('&gt;', '>')
    return content

def get_real_extension(response):
    """æ™ºèƒ½åç¼€è¯†åˆ«"""
    ctype = response.headers.get("Content-Type", "").lower()
    if "amr" in ctype: return ".amr"
    if "wav" in ctype: return ".wav"
    if "mpeg" in ctype or "mp3" in ctype or "audio" in ctype: return ".mp3"
    if "png" in ctype: return ".png"
    if "gif" in ctype: return ".gif"
    return ".jpg"

def download_resource(fid):
    """ä¸‡èƒ½èµ„æºä¸‹è½½å™¨ (å¢é‡ + æ¥å£ç©·ä¸¾)"""
    # å¢é‡è·³è¿‡
    for ext in [".jpg", ".png", ".gif", ".mp3", ".amr", ".wav", ".m4a", ".webp"]:
        fname = f"{fid}{ext}"
        fpath = os.path.join(ASSETS_DIR, fname)
        if os.path.exists(fpath) and os.path.getsize(fpath) > 1000:
            return fname

    # æ¥å£ç©·ä¸¾
    headers = get_headers()
    types = ["note_img", "file", "note_voice", "note_audio"]
    for tp in types:
        try:
            url = f"https://i.mi.com/file/full?type={tp}&fileid={fid}"
            r = requests.get(url, headers=headers, stream=True, timeout=10)
            if r.status_code == 200:
                if int(r.headers.get('content-length', 0)) < 1000: continue
                real_ext = get_real_extension(r)
                fname = f"{fid}{real_ext}"
                with open(os.path.join(ASSETS_DIR, fname), "wb") as f:
                    for chunk in r.iter_content(1024): f.write(chunk)
                return fname
        except: pass
    return None

def fetch_note_list():
    """çˆ¬è™«ï¼šè‡ªåŠ¨ç¿»é¡µè·å–åˆ—è¡¨"""
    print("ğŸ“¡ æ­£åœ¨è¿æ¥å°ç±³äº‘æœåŠ¡...")
    headers = get_headers()
    all_entries = []
    folders_map = {'0': 'æœªåˆ†ç±»'}
    sync_tag = None
    
    while True:
        url = f"https://i.mi.com/note/full/page/?limit=200&ts={int(time.time()*1000)}"
        if sync_tag: url += f"&syncTag={sync_tag}"
        
        try:
            r = requests.get(url, headers=headers, timeout=10)
            if r.status_code == 401:
                print("âŒ Cookie å·²å¤±æ•ˆï¼Œè¯·é‡æ–°è·å–ï¼")
                return None, None
                
            data = r.json().get('data', {})
            
            for f in data.get('folders', []):
                folders_map[str(f.get('id'))] = f.get('subject')
            
            entries = data.get('entries', [])
            all_entries.extend(entries)
            print(f"    å·²ç´¢å¼• {len(all_entries)} æ¡ç¬”è®°...")
            
            sync_tag = data.get('syncTag')
            if not sync_tag: break
            time.sleep(0.5)
        except Exception as e:
            print(f"âŒ ç½‘ç»œè¯·æ±‚é”™è¯¯: {e}")
            break
            
    return all_entries, folders_map

def fetch_note_detail(note_id):
    """è·å–è¯¦æƒ…"""
    url = f"https://i.mi.com/note/note/{note_id}/?ts={int(time.time()*1000)}"
    try:
        r = requests.get(url, headers=get_headers(), timeout=10)
        return r.json().get('data', {}).get('entry')
    except:
        return None

def process_single_note(args):
    """å•æ¡ç¬”è®°å¤„ç†æµç¨‹ (å«å¢é‡æ£€æµ‹)"""
    entry, folder_map = args
    nid = entry['id']
    
    # è·¯å¾„è®¡ç®—
    folder_id = str(entry.get('folderId', '0'))
    folder_name = folder_map.get(folder_id, "æœªåˆ†ç±»")
    
    extra = {}
    try: extra = json.loads(entry.get('extraInfo', '{}'))
    except: pass
    
    title = extra.get('title') or entry.get('snippet', 'æ— æ ‡é¢˜')
    title = sanitize_filename(title)
    if not title: title = f"æ— æ ‡é¢˜_{nid}"
    
    date_str = time.strftime("%Y%m%d", time.localtime(entry['createDate']/1000))
    target_dir = os.path.join(VAULT_ROOT, sanitize_filename(folder_name))
    md_path = os.path.join(target_dir, f"{date_str}_{title}.md")
    
    # === å¢é‡æ£€æµ‹ ===
    if os.path.exists(md_path):
        return # æœ¬åœ°å·²å­˜åœ¨ï¼Œè·³è¿‡
        
    # === ä¸‹è½½ä¸å¤„ç† ===
    full_note = fetch_note_detail(nid)
    if not full_note: return
    content = full_note.get('content', '')
    
    if not os.path.exists(target_dir): 
        os.makedirs(target_dir, exist_ok=True)
    
    # æå–èµ„æºID
    ids = set()
    ids.update(re.findall(r'fileid=["\']?([\w\.\-]+)["\']?', content, re.I))
    ids.update(re.findall(r'â˜º\s*([\w\.\-]+)', content))
    ids.update(re.findall(r'<fileId:(\d+)', content))
    ids.update(re.findall(r'<sound[^>]+fileid=["\']?([\w\.\-]+)["\']?', content, re.I))
    
    voice_list = extra.get('voice_list') or extra.get('audio_list') or []
    voice_ids = [v['fileId'] for v in voice_list if v.get('fileId')]
    ids.update(voice_ids)
    
    if full_note.get('setting'):
        try:
            for res in json.loads(full_note.get('setting', '{}')).get('data', []):
                if res.get('fileId'): ids.add(res.get('fileId'))
        except: pass

    # ä¸‹è½½èµ„æº
    replacements = {}
    for fid in ids:
        fname = download_resource(fid)
        if fname:
            replacements[fid] = f"![[{fname}]]"

    # æ¸…æ´—ä¸æ›¿æ¢
    content = clean_content(content)
    for fid, link in replacements.items():
        content = re.sub(fr'<sound[^>]*{re.escape(fid)}[^>]*\/?>', f"\n{link}\n", content)
        content = re.sub(fr'<[^>]*{re.escape(fid)}[^>]*>', f"\n{link}\n", content)
        content = re.sub(fr'â˜º\s*{re.escape(fid)}.*', f"\n{link}\n", content)
        content = content.replace(f"<fileId:{fid}>", f"\n{link}\n")
        content = content.replace(f"<fileId:{fid}/>", f"\n{link}\n")

    # è¿½åŠ å½•éŸ³
    if voice_ids:
        appended = False
        for vid in voice_ids:
            if vid not in content and vid in replacements:
                if not appended:
                    content += "\n\n---\n**ğŸ™ï¸ é™„ä»¶å½•éŸ³ï¼š**\n"
                    appended = True
                content += f"{replacements[vid]}\n"

    # ç”Ÿæˆ Markdown
    ctime = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(full_note['createDate']/1000))
    mtime = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(full_note['modifyDate']/1000))
    
    md_text = f"---\nid: {nid}\ncreated: {ctime}\nupdated: {mtime}\ntitle: \"{title}\"\nfolder: \"{folder_name}\"\nauthor: Ning\n---\n\n# {title}\n\n{content}\n"
    
    with open(md_path, "w", encoding="utf-8") as f:
        f.write(md_text)
    print(f"    âœ… åŒæ­¥æˆåŠŸ: [{folder_name}] {title}")

def main():
    print(f"ğŸš€ MiNote Sync Pro - By Ning")
    setup_dirs()
    
    notes_list, folder_map = fetch_note_list()
    if not notes_list: return

    print(f"ğŸ“¦ å‘ç°äº‘ç«¯ç¬”è®° {len(notes_list)} æ¡ï¼Œå¼€å§‹å¢é‡åŒæ­¥...")
    
    with ThreadPoolExecutor(max_workers=8) as pool:
        pool.map(process_single_note, [(n, folder_map) for n in notes_list])
        
    print(f"\nğŸ‰ å…¨éƒ¨åŒæ­¥å®Œæˆï¼æ•°æ®å·²ä¿å­˜è‡³: {VAULT_ROOT}")

if __name__ == "__main__":
    main()